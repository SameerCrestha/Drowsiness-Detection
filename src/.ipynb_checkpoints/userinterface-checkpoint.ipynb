{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "10a0c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "from playsound import playsound\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import time\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import winsound\n",
    "EYE_AR_THRESH = 0.27\n",
    "MAR_THRESH=0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c45e4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    # return the eye aspect ratio\n",
    "    return ear\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(mouth[1], mouth[7])\n",
    "    B = dist.euclidean(mouth[2], mouth[6])\n",
    "    C = dist.euclidean(mouth[3], mouth[5])\n",
    "#     D = dist.euclidean(mouth[4], mouth[8])\n",
    "#     E = dist.euclidean(mouth[5], mouth[7])\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    F = dist.euclidean(mouth[0], mouth[4])\n",
    "    # compute the eye aspect ratio\n",
    "    mouth = (A + B +C) / (3.0 * F)\n",
    "    # return the eye aspect ratio\n",
    "    return mouth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "631c643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "[INFO] loading facial landmark predictor...\n",
      "[INFO] starting video stream thread...\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.3\n",
      "0.27\n",
      "0.3\n",
      "0.27\n",
      "0.27\n",
      "0.3\n",
      "0.27\n",
      "0.3\n",
      "0.27\n",
      "0.3\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.3\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n",
      "0.27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class App:\n",
    "    def __init__(self, master,EYETHR,MARTHR):\n",
    "        self.my_var1 = tk.DoubleVar()\n",
    "        self.my_var2 = tk.DoubleVar()\n",
    "        self.EYETHR=0\n",
    "        self.MARTHR=0\n",
    "        self.my_var1.set(EYETHR)\n",
    "        self.my_var2.set(MARTHR)\n",
    "        self.master = master\n",
    "        master.title(\"Real Time Drowsiness Detection System\")\n",
    "\n",
    "        self.title_label = tk.Label(master, text=\"Real Time Drowsiness Detection System\", font=('Arial', 20))\n",
    "        self.title_label.pack(pady=20)\n",
    "\n",
    "        self.calibrate_button = tk.Button(master, text=\"Calibrate\", font=('Arial', 12), command=self.open_window, padx=20, pady=10)\n",
    "        self.calibrate_button.pack(pady=20,padx=20)\n",
    "\n",
    "        self.start_button = tk.Button(master, text=\"Start\", font=('Arial', 12), command=self.start, padx=20, pady=10)\n",
    "        self.start_button.pack(pady=20,padx=20)\n",
    "        \n",
    "        self.start_button = tk.Button(master, text=\"Guidelines\", font=('Arial', 10), command=self.guide, padx=20, pady=10)\n",
    "        self.start_button.pack(pady=20,padx=20)\n",
    "        self.var1_label = tk.Label(master, text=\"Current EAR Threshold:\", font=('Arial', 16))\n",
    "        self.var1_label.pack(pady=10)\n",
    "        my_label = tk.Label(master, textvariable=str(self.my_var1),font=('Arial', 16))\n",
    "        my_label.pack()\n",
    "        self.var1_value = tk.Label(master, text=\"Current MAR Threshold:\", font=('Arial', 16))\n",
    "        self.var1_value.pack(pady=10)\n",
    "        my_label = tk.Label(master, textvariable=str(self.my_var2),font=('Arial', 16))\n",
    "        my_label.pack()\n",
    "    def guide(self):\n",
    "            new = tk.Toplevel()\n",
    "            self.var4_label = tk.Label(new, text=\"GUIDELINES\", font=('Arial', 20))\n",
    "            self.var4_label.pack(pady=10)\n",
    "            self.var4_label = tk.Label(new, text=\"1. Place Your camera slightly above face level.\", font=('Arial', 16))\n",
    "            self.var4_label.pack(pady=20)\n",
    "            self.var4_label = tk.Label(new, text=\"2. Adjust Camera angle such that it is facing the face.\", font=('Arial', 16))\n",
    "            self.var4_label.pack(pady=10)\n",
    "            self.var4_label = tk.Label(new, text=\"3. Proper lighting conditions will give proper accuracy.\", font=('Arial', 16))\n",
    "            self.var4_label.pack(pady=10)\n",
    "            self.var4_label = tk.Label(new, text=\"4. Photos used in calibration should be taken from same orientation as mentioned in 1 and 2.\", font=('Arial', 16))\n",
    "            self.var4_label.pack(pady=10)\n",
    "    def open_window(self):\n",
    "    # Create a new window\n",
    "        new_window = tk.Toplevel()\n",
    "    \n",
    "    # Add some content to the window\n",
    "        label = tk.Label(new_window, text=\"CALIBRATION\",font=('Arial', 20))\n",
    "        label.pack()\n",
    "        self.calibrate_button = tk.Button(new_window, text=\"Upload image with eye open and mouth closed\", font=('Arial', 12), command=self.calibrate, padx=20, pady=10)\n",
    "        self.calibrate_button.pack(pady=20,padx=20)\n",
    "        self.calibrate_button = tk.Button(new_window, text=\"Upload image with eye close and mouth open\", font=('Arial', 12), command=self.calibrate, padx=20, pady=10)\n",
    "        self.calibrate_button.pack(pady=20,padx=20)\n",
    "        self.calibrate_button = tk.Button(new_window, text=\"OK\", font=('Arial', 16), command=self.calculationthreshold, padx=20, pady=10)\n",
    "        self.calibrate_button.pack(pady=20,padx=20)\n",
    "    def calculationthreshold(self):\n",
    "        global EYE_AR_THRESH\n",
    "        global MAR_THRESH\n",
    "        self.my_var1.set(self.EYETHR/2)\n",
    "        self.my_var2.set(self.MARTHR/2)\n",
    "        EYE_AR_THRESH = self.EYETHR/2\n",
    "        MAR_THRESH=self.MARTHR/2\n",
    "        print(EYE_AR_THRESH)\n",
    "        print(MAR_THRESH)\n",
    "    def calibrate(self):\n",
    "        print(\"Calibrating...\")\n",
    "        lStart=6\n",
    "        lEnd=11\n",
    "        rStart=0\n",
    "        rEnd=5\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        # Load the detector\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        \n",
    "        # Load the predictor\n",
    "        predictor = dlib.shape_predictor(\"../img/predictor.dat\")\n",
    "        \n",
    "        # Load the image\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces in the grayscale image\n",
    "        faces = detector(gray,0)\n",
    "        if not faces:\n",
    "                return 0\n",
    "        rect=faces[0]\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        leftEye = shape[lStart:(lEnd+1)]\n",
    "        rightEye = shape[rStart:(rEnd+1)]\n",
    "        mouth=shape[lEnd+1:(24)]\n",
    "        internalmouth=shape[24:32]\n",
    "        mouthMAR=mouth_aspect_ratio(internalmouth)\n",
    "        print(mouthMAR)\n",
    "        print(self.MARTHR)\n",
    "        self.MARTHR=self.MARTHR+mouthMAR\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        # average the eye aspect ratio together for both eyes\n",
    "        print((leftEAR + rightEAR) / 2.0)\n",
    "        self.EYETHR  = self.EYETHR + (leftEAR + rightEAR) / 2.0\n",
    "        print(self.EYETHR)\n",
    "        print(self.MARTHR)\n",
    "    def start(self):\n",
    "        print(\"Starting...\")\n",
    "# define two constants, one for the eye aspect ratio to indicate\n",
    "# blink and then a second constant for the number of consecutive\n",
    "# frames the eye must be below the threshold for to set off the\n",
    "# alarm\n",
    "        \n",
    "        EYE_AR_CONSEC_FRAMES = 30\n",
    "        MOUTH_FRAMES= 30\n",
    "# initialize the frame counter as well as a boolean used to\n",
    "# indicate if the alarm is going off\n",
    "        COUNTER = 0\n",
    "        counterMouth=0\n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "        print(\"[INFO] loading facial landmark predictor...\")\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        predictor = dlib.shape_predictor(\"predictor.dat\")\n",
    "        lStart=6\n",
    "        lEnd=11\n",
    "        rStart=0\n",
    "        rEnd=5\n",
    "        # start the video stream thread\n",
    "        print(\"[INFO] starting video stream thread...\")\n",
    "        vs = VideoStream(src=0).start()\n",
    "        time.sleep(1.0)\n",
    "        # used to record the time when we processed last frame\n",
    "        prev_frame_time = 0\n",
    "          \n",
    "        # used to record the time at which we processed current frame\n",
    "        new_frame_time = 0\n",
    "        ear=0\n",
    "        \n",
    "        # loop over frames from the video stream\n",
    "        while True:\n",
    "            \n",
    "            frame = vs.read()\n",
    "            frame = imutils.resize(frame, width=600)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            rect = detector(gray, 0)\n",
    "            # Calculating the fps\n",
    "            new_frame_time = time.time()\n",
    "                # fps will be number of frame processed in given time frame\n",
    "                # since their will be most of time error of 0.001 second\n",
    "                # we will be subtracting it to get more accurate result\n",
    "            fps = 1/(new_frame_time-prev_frame_time)\n",
    "            prev_frame_time = new_frame_time\n",
    "              \n",
    "                # converting the fps into integer\n",
    "            fps = int(fps)\n",
    "                # converting the fps to string so that we can display it on frame\n",
    "           \n",
    "            if not rect:\n",
    "                cv2.putText(frame, \"No FACE DETECTED\",\n",
    "                            (200, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"FPS :\"+str(fps), (20, 400),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"Press q to exit\", (300, 400),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                \n",
    "                cv2.imshow(\"Frame\", frame)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "            \n",
    "                \n",
    "                \n",
    "                rect=rect[0]\n",
    "                shape = predictor(gray, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                # extract the left and right eye coordinates, then use the\n",
    "                # coordinates to compute the eye aspect ratio for both eyes\n",
    "                leftEye = shape[lStart:(lEnd+1)]\n",
    "                rightEye = shape[rStart:(rEnd+1)]\n",
    "                mouth=shape[lEnd+1:(24)]\n",
    "                internalmouth=shape[24:32]\n",
    "                mouthMAR=mouth_aspect_ratio(internalmouth)\n",
    "                \n",
    "                leftEAR = eye_aspect_ratio(leftEye)\n",
    "                rightEAR = eye_aspect_ratio(rightEye)\n",
    "                # average the eye aspect ratio together for both eyes\n",
    "                ear = (leftEAR + rightEAR) / 2.0\n",
    "                # compute the convex hull for the left and right eye, then\n",
    "                # visualize each of the eyes\n",
    "                leftEyeHull = cv2.convexHull(leftEye)\n",
    "                rightEyeHull = cv2.convexHull(rightEye)\n",
    "                mouthHull=cv2.convexHull(mouth)\n",
    "                internalmouthHull=cv2.convexHull(internalmouth)\n",
    "                cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [mouthHull], -1, (0, 255, 0), 1)\n",
    "                cv2.drawContours(frame, [internalmouthHull], -1, (0, 255, 0), 1)\n",
    "                # check to see if the eye aspect ratio is below the blink\n",
    "                # threshold, and if so, increment the blink frame counter\n",
    "                if ear < EYE_AR_THRESH:\n",
    "                    print(EYE_AR_THRESH)\n",
    "                    COUNTER += 1\n",
    "                    # if the eyes were closed for a sufficient number of\n",
    "                    # then sound the alarm\n",
    "                    if COUNTER >= fps*2:\n",
    "                        # if the alarm is not on, turn it on\n",
    "                        winsound.Beep(1000, 1000) \n",
    "                        cv2.putText(frame, \"DROWSINESS ALERT!\", (250, 20),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    COUNTER = 0\n",
    "              \n",
    "                    \n",
    "                    \n",
    "                #for MAR\n",
    "                if mouthMAR > MAR_THRESH:\n",
    "                    print(MAR_THRESH)\n",
    "                    counterMouth += 1\n",
    "                    if counterMouth >=  fps*5:\n",
    "                        winsound.Beep(1000, 1000) \n",
    "                        cv2.putText(frame, \"YAWN ALERT!\", (250, 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                else:\n",
    "                    counterMouth = 0\n",
    "                    # draw the computed eye aspect ratio on the frame to help\n",
    "                    # with debugging and setting the correct eye aspect ratio\n",
    "                    # thresholds and frame counters\n",
    "                cv2.putText(frame, \"EAR:{:.2f}\".format(ear), (500, 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"MAR:{:.2f}\".format(mouthMAR), (20, 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"FPS :\"+str(fps), (20, 400),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                \n",
    "                cv2.putText(frame, \"Press q to exit\", (300, 400),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        vs.stop() \n",
    "\n",
    "root = tk.Tk()\n",
    "app = App(root,EYE_AR_THRESH,MAR_THRESH)\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a007f140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950fc87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
